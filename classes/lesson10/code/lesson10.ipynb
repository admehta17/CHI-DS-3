{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Predicting Evergreeness of Content with Decision Trees and Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "Let's imagine you were making a recommendation engine.\n",
    "\n",
    "You want to make recommendations about sites that are always useful (and not just useful for a short period of time).\n",
    "\n",
    "We can call this quality of ALWAYS being relevant as being <u>\"Evergreen\"</u>\n",
    "\n",
    "StumbleUpon is a recommendation service with this goal in mind.\n",
    "\n",
    "Specifically, users have an extension that recommended websites to them, and that users can click to indicate a site they like.\n",
    "\n",
    "The problem is deciding whether the site that users liked should also be recommended to others.\n",
    "\n",
    "StumbleUpon needs to know if the site a user provided is Evergreen (always useful to others).\n",
    "\n",
    "Therefore, StumbleUpon needs a classifier that can determine whether a site is Evergreen or not, based on the information they have about it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting \"Evergreeness\" Of Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset comes from [stumbleupon](https://www.stumbleupon.com/).\n",
    "\n",
    "It contains webpages suggested by users, basic meta-data from the website, as well as a user-provided label for whether the site is \"Evergreen\" or not.\n",
    "\n",
    "From this data, we can train a classifier to predict whether a website is Evergreen.\n",
    "\n",
    "A description of the columns is below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FieldName|Type|Description\n",
    "---------|----|-----------\n",
    "url|string|Url of the webpage to be classified\n",
    "title|string|Title of the article\n",
    "body|string|Body text of article\n",
    "urlid|integer| StumbleUpon's unique identifier for each url\n",
    "boilerplate|json|Boilerplate text\n",
    "alchemy_category|string|Alchemy category (per the publicly available Alchemy API found at www.alchemyapi.com)\n",
    "alchemy_category_score|double|Alchemy category score (per the publicly available Alchemy API found at www.alchemyapi.com)\n",
    "avglinksize| double|Average number of words in each link\n",
    "commonlinkratio_1|double|# of links sharing at least 1 word with 1 other links / # of links\n",
    "commonlinkratio_2|double|# of links sharing at least 1 word with 2 other links / # of links\n",
    "commonlinkratio_3|double|# of links sharing at least 1 word with 3 other links / # of links\n",
    "commonlinkratio_4|double|# of links sharing at least 1 word with 4 other links / # of links\n",
    "compression_ratio|double|Compression achieved on this page via gzip (measure of redundancy)\n",
    "embed_ratio|double|Count of number of <embed> usage\n",
    "frameBased|integer (0 or 1)|A page is frame-based (1) if it has no body markup but have a frameset markup\n",
    "frameTagRatio|double|Ratio of iframe markups over total number of markups\n",
    "hasDomainLink|integer (0 or 1)|True (1) if it contains an <a> with an url with domain\n",
    "html_ratio|double|Ratio of tags vs text in the page\n",
    "image_ratio|double|Ratio of <img> tags vs text in the page\n",
    "is_news|integer (0 or 1) | True (1) if StumbleUpon's news classifier determines that this webpage is news\n",
    "lengthyLinkDomain| integer (0 or 1)|True (1) if at least 3 <a> 's text contains more than 30 alphanumeric characters\n",
    "linkwordscore|double|Percentage of words on the page that are in hyperlink's text\n",
    "news_front_page| integer (0 or 1)|True (1) if StumbleUpon's news classifier determines that this webpage is front-page news\n",
    "non_markup_alphanum_characters|integer| Page's text's number of alphanumeric characters\n",
    "numberOfLinks|integer Number of <a>|markups\n",
    "numwords_in_url| double|Number of words in url\n",
    "parametrizedLinkRatio|double|A link is parametrized if it's url contains parameters or has an attached onClick event\n",
    "spelling_errors_ratio|double|Ratio of words not found in wiki (considered to be a spelling mistake)\n",
    "label|integer (0 or 1)|User-determined label. Either evergreen (1) or non-evergreen (0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in the Data\n",
    "\n",
    "Let's first read in the data into a pandas dataframe\n",
    "\n",
    "The data are not comma separated as usual, but rather separated by tabs.\n",
    "\n",
    "We can tell pandas to treat tabs as the delimeter by indicating that the field separator is '\\t'\n",
    "\n",
    "We do this using the command: sep = '\\t'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Tell the pandas csv reader that our file has the fields separated by a tab (\\t)\n",
    "#We'll drop rows with missing values for simplicity, but typically you would want to imput those values\n",
    "df = pd.read_csv(\"stumbleupon.tsv\", sep='\\t').dropna()\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reminder: What are 'evergreen' sites?\n",
    "\n",
    "Evergreen sites are those that are always relevant.  As opposed to breaking news or current events, evergreen websites are relevant no matter the time or season. \n",
    "\n",
    "A sample of URLs is below, where label = 1 are 'evergreen' websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[['url', 'label']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Exercises to Get Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: 1. Brainstorm 2 - 4 new features you could develop that would be useful for predicting evergreen websites based on the titles.\n",
    " \n",
    "- Example: One feature could be a dummy variable for if the webpage is a recipe or not. Presumably recipes are always useful\n",
    " \n",
    "###  Exercise: 2. After looking at the dataset, can you model or quantify any of the characteristics you wanted?\n",
    "- If you believe high-image content websites are likely to be evergreen, how can you build a feature that represents that?\n",
    "\n",
    "- Example: If you think websites with recipes are likely to be evergreen, you could make a column that corresponds to whether or not the word recipe in the title.\n",
    "\n",
    "### Exercise: 3. Implementing your feature ideas\n",
    "\n",
    "- We can make a feature that works looks for keywords in the text field by applying a function to the relevant column\n",
    "\n",
    "- We can also use a string command to accomplish the same\n",
    "\n",
    "- Example: Make a feature that codes whether the website has the word recipe in the title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Option 1: Create a function to check for this\n",
    "\n",
    "def has_recipe(content):\n",
    "    try:\n",
    "        if 'recipe' in str(content).lower():\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    except: \n",
    "        return 0\n",
    "        \n",
    "df['recipe'] = df['title'].apply(has_recipe)\n",
    "\n",
    "\n",
    "# Option 2: string functions\n",
    "\n",
    "df['recipe'] = df['title'].str.contains('recipe')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the results\n",
    "\n",
    "We can check to see if our function worked by subsetting our data to only have the rows where recipe  = 1 \n",
    "\n",
    "<i>df[df.recipe == 1]</i>\n",
    "\n",
    "and then printing the title for those rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print df[df.recipe == 1]['title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create your own Predictors\n",
    "\n",
    "In the previous example, we thought that recipes would probably be more consistently useful. Are there any other keywords you can think of, that, if they were in the title or body of the website, they would indicate a website as likely being evergreen.\n",
    "\n",
    "In the space below, feel free to try to implement your ideas from Exercise 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#  Let's Explore Using Decision Trees To Classify our Websites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Build a decision tree model to predict the \"evergreeness\" of a given website. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll import the library to make the decision tree.\n",
    "\n",
    "Next, we'll make a decision tree classifier object.\n",
    "\n",
    "We'll keep the tree simple for now, so we'll specify that the tree can only have two levels at most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier(max_depth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll build the dataframe that just has the predictors (image_ratio and recipe).\n",
    "\n",
    "In this example, we'll use the ratio of images to text on the webpage and whether the site has the word 'recipe' in the title.\n",
    "\n",
    "And then we'll build the dataframe that just has the outcome (whether the site was labeled as evergreen or not)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's subset the dataframe to only have the \n",
    "predictors = ['image_ratio','recipe']\n",
    "X = df[predictors]\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next we'll fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's visualize the tree\n",
    "\n",
    "What we're going to do is create a function that take our model in.\n",
    "\n",
    "We'll then create an IO object that acts as a fake file for writing the data to.\n",
    "\n",
    "We'll then use the export_graphviz function from sklearn to write our model to the graphviz format and save the data in our fake file.\n",
    "\n",
    "Last, we'll get the data that was written to the file, and then print it.\n",
    "\n",
    "We can then use Graphviz to visualize it. \n",
    "\n",
    "Graphviz is a free program that reads in a graph stored in the \"dot\" format, and converts it to a labeled image\n",
    "\n",
    "You don't need to have Graphviz installed on your computer.\n",
    "\n",
    "Instead, you can copy the printed information and paste in the following website:\n",
    "    http://www.webgraphviz.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import StringIO\n",
    "def build_tree_image(model):\n",
    "    dotfile = StringIO.StringIO()\n",
    "    export_graphviz(model,out_file = dotfile, feature_names = X.columns)\n",
    "   \n",
    "    #If you had Graphviz installed on your computer, you would uncomment the folloing lines of code\n",
    "    # dotfile = open(\"tree.dot\",\"wb\")\n",
    "    # export_graphviz(model,out_file = dotfile, feature_names = X.columns)\n",
    "    return dotfile.getvalue()\n",
    "    \n",
    "print build_tree_image(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the contribution of each feature\n",
    "\n",
    "Altough decision trees are non-linear, you can still have a general sense of which predictor contributed the most to your classifications.\n",
    "\n",
    "Specifically, the feature importance is the (normalized to sum to 1) total reduction in our purity brought about by that feature in the tree. If a feature is able to split the data in half, and narrow the category down a lot, then it has a lot of importance.\n",
    "\n",
    "On our trained model, we can call the \"feature\\_importances_\" command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can associate the feature with the predictor name using the zip command.\n",
    "\n",
    "The zip command matches up elements from two lists and groups them in a single list.\n",
    "\n",
    "It appears that recipe had roughly twice the importance of image ratio when classifying whether the webpage is an evergreen site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zip(predictors, model.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating performance\n",
    "\n",
    "We can see how our classifier performed, similar to how we evaluated the performance of our logistic regression and KNN classifier.\n",
    "\n",
    "We'll first build a K-fold cross-validation object that splits our data into training and test sets.\n",
    "\n",
    "For each fold, we'll fit the model on the training set of data, and then test out the performance on the training set.\n",
    "\n",
    "We'll then see what the average performance was across all folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "#make a cross validation object for 10 folds\n",
    "kfold = cross_validation.KFold(len(X), n_folds=10)\n",
    "\n",
    "#using our model, fit a subset of the X data on a subset of the y data \n",
    "#using the kfold object to decide how to split the data\n",
    "#using the area under the curve as our scoring metric for how well our model is making predictions\n",
    "cv_scores = cross_validation.cross_val_score(model, X, y, cv=kfold,scoring='roc_auc')\n",
    "\n",
    "#print off all of the cross-validation scores\n",
    "print cv_scores\n",
    "\n",
    "#print the average cross-validation score; \n",
    "#for Area under the Curve, anything above .50, is an improvement over chance\n",
    "print cv_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Adding More Predictors and Increasing the Depth\n",
    "\n",
    "Right now, our decision tree is limited to a depth of 2, and only has two predictors.\n",
    "\n",
    "Try to increase the Area under the Curve Score by increasing the number of predictors.\n",
    "\n",
    "Below are the variable names to choose from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictors = ['','','']\n",
    "X = df[predictors]\n",
    "y= df['label']\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "cv_scores = cross_validation.cross_val_score(model, X, y, cv=kfold,scoring='roc_auc')\n",
    "print mean(cv_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#  Adjusting Decision Trees to Avoid Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now, your decision tree is unconstrained in terms of it's depth and the minimum samples needed for a leaf to exist.\n",
    "\n",
    "Let's try out different values for the depth it can take and the minimum number of samples needed for a leaf before we stop splitting.\n",
    "\n",
    "We've seen the grid search function before.\n",
    "\n",
    "We give it our classifier and a list of parameters we want it to try on the classifier, and when we fit a model to it, grid search tries out all of the combinations of paramters you give it.\n",
    "\n",
    "To use grid search, you need to provide a dictionary, where each key is the parameter, and we provide a list containing the different values we want it to try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "max_depth_values = [2,3,4,5,6,7,8,9,10,12,13]\n",
    "min_samples_leaf_values = [6,7,8,9,10,11,12,13,14]\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "params = {'max_depth':max_depth_values,'min_samples_leaf':min_samples_leaf_values}\n",
    "clf = GridSearchCV(model, params, cv=5,scoring='roc_auc')\n",
    "clf.fit(X, y)\n",
    "\n",
    "clf.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the Best Parameter Values\n",
    "\n",
    "We can sort through the list of grid scores, by using the sorted function.\n",
    "\n",
    "Right now, our grid scores are a list of tuples (a tuple is just a collection of objects, similar to a list)\n",
    "\n",
    "In each tuple, we have the mean AUC, the standard deviation of the scores, and the parameter combination.\n",
    "\n",
    "We want to sort the list of tuples by the first element in the tuple (the mean score). So we'll tell the sorted function to sort by the first (0th) element in the tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted(clf.grid_scores_,key=lambda x:x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We've been focusing on building decision trees, but we can also build a random forest classifier that uses many different decision trees to classify our data.\n",
    "\n",
    "We will simply create a RandomForestClassifier object and indicate how many different decision trees we want to include.\n",
    "\n",
    "If n_estimators was equal to 1, then we would get similar performance to our decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators = 20)\n",
    "    \n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting importance of features\n",
    "\n",
    "Similar to our decision tree context, we can also get the relative importance of each feature in our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = predictors\n",
    "feature_importances = model.feature_importances_\n",
    "\n",
    "features_df = pd.DataFrame({'Features': features, 'Importance Score': feature_importances})\n",
    "features_df.sort_values('Importance Score', inplace=True, ascending=False)\n",
    "\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Exercise: Evaluate the Random Forest model using cross-validation; increase the number of estimators and view how that improves predictive performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Independent Practice: Evaluate Random Forest Using Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Continue adding input variables to the model that you think may be relevant\n",
    "2. For each feature:\n",
    "  - Evaluate the model for improved predictive performance using cross-validation\n",
    "  - Evaluate the _importance_ of the feature\n",
    "  - \n",
    "3. **Bonus**: Just like the 'recipe' feature, add in similar text features and evaluate their performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a reminder of the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "predictors = ['image_ratio', 'recipe']\n",
    "# Building a model with more relevant features\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=50)\n",
    "\n",
    "# Continue to add features to X\n",
    "#     Build dummy features, include quantitative features, or add text features\n",
    "X = df[predictors]\n",
    "\n",
    "y = df['label']\n",
    "\n",
    "# Evaluate predictive performance for the given feature set\n",
    "scores = cross_validation.cross_val_score(model, X, y, cv=10,scoring='roc_auc')\n",
    "\n",
    "#print the average cross-validated Area Under the Curve for that model\n",
    "print 'Average AUC %f' % scores.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
