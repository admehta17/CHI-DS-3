{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data into a pandas dataframe\n",
    "\n",
    "We will be using machine learning to try to determine the species that different flowers belong to based on their measurements.\n",
    "\n",
    "The data set consists of 50 samples from each of three species of Iris (\"Iris setosa\", \"Iris virginica\", and \"Iris versicolor\"). \n",
    "\n",
    "Four features were measured from each sample: the length and the width of the sepals and petals, in centimetres. Based on the combination of these four features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Load the data from the sklearn datasets library\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "#save the predictor data to a Pandas dataframe\n",
    "\n",
    "irisdf = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "\n",
    "#Save the class labels (i.e., the species of every row) as a column called \"species\"\n",
    "irisdf['species'] = iris.target\n",
    "\n",
    "#Let's see the first 10 rows of the data\n",
    "print irisdf.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initital Visualization\n",
    "\n",
    "Plot each data point in terms of its \"Petal Length\" and \"Petal Width\"\n",
    "\n",
    "We know what the the actual species is for each data point, so we'll color the point according the species in the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cmap = {'0': 'r', '1': 'g', '2': 'b' }\n",
    "irisdf['ctarget'] = irisdf.species.apply(lambda x: cmap[str(x)])\n",
    "irisdf.plot('petal length (cm)', 'petal width (cm)', kind='scatter', c=irisdf.ctarget)\n",
    "print irisdf.plot('petal length (cm)', 'petal width (cm)', kind='scatter', c=irisdf.ctarget)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbor (KNN) Classifier\n",
    "\n",
    "Let's build a K-Nearest neighbor classifier to classify the species based on their measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "# n_neighbors is our option in KNN. We'll tune this value to attempt to improve our prediction.\n",
    "predictors = [\"sepal length (cm)\", \"sepal width (cm)\", \"petal length (cm)\",  \"petal width (cm)\"]\n",
    "\n",
    "#you could also do this to get the column names except for the last one\n",
    "predictors = irisdf.columns[:-1]\n",
    "\n",
    "X = irisdf[predictors]\n",
    "\n",
    "labels=irisdf['species']\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=5, weights='uniform')\n",
    "knn.fit(X, labels)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification metrics\n",
    "\n",
    "Print out the performance of the classifer for different classification metrics\n",
    "\n",
    "Confusion matrix\n",
    "\n",
    "Accurracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "Precision = TP / (TP + FN)\n",
    "\n",
    "Recall = TP / (TP + FP)\n",
    "\n",
    "F1 Score = (Precision * Recall) / (Precision + Recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "predicted = knn.predict(X)\n",
    "\n",
    "\n",
    "print metrics.confusion_matrix(labels,predicted)\n",
    "\n",
    "print \"Accuracy: %f\" % metrics.accuracy_score(labels,predicted)\n",
    "\n",
    "print \"Precision: %f\" % metrics.precision_score(labels,predicted,average='weighted')\n",
    "\n",
    "print \"Recall: %f \" % metrics.recall_score(labels,predicted,average='weighted')\n",
    "\n",
    "print \"F1 Score: %f\" % metrics.f1_score(labels,predicted,average='weighted')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the Best value for \"K\"\n",
    "\n",
    "Sklearn has a function to try out all of the different parameter values for a range that you provide. It then can go through trying each value and seeing what the average cross-validated score for that parameter was.\n",
    "\n",
    "All of the cross-validated scores will be saved and you can print them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import grid_search, cross_validation\n",
    "\n",
    "#set the range of possible K-values: We'll choose all integers from 2 to 100\n",
    "k = range(2, 100)\n",
    "#Make a dictionary that will hold the value we will pass on to the KNeighborsClassifier() function\n",
    "params = {'n_neighbors': k }\n",
    "\n",
    "#Make a cross-validation iterator with 5 folds\n",
    "kf = cross_validation.KFold(len(irisdf), n_folds = 5)\n",
    "\n",
    "# Set up a grid search to try every combination of K, \n",
    "#We'll use accuracy as our scoring criterion for the search, \n",
    "#but you can set it to the name of another classifer\n",
    "gs = grid_search.GridSearchCV(\n",
    "    estimator=neighbors.KNeighborsClassifier(),\n",
    "    param_grid=params,\n",
    "    cv=kf,\n",
    "    scoring = 'accuracy'\n",
    ")\n",
    "gs.fit(X, labels)\n",
    "gs.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try out the best fitting estimator\n",
    "\n",
    "The best fitting KNN classifier from the grid search will be saved and you can use it to predict new values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted = gs.predict(X)\n",
    "print metrics.accuracy_score(labels,predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the cross validated accuracy of different values for K\n",
    "\n",
    "You can visualize the accuracy for each K-value by plotting the K-value on the X-axis and the Accuracy of that K-value on the Y-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(k,[s[1] for s in  gs.grid_scores_],)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoom into the area where you think the accuracy is at its highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fill in the lower and upper bound for where you want to zoom into.\n",
    "# For exmaple, if you think that accuracy is highest when K = 20, \n",
    "# then choose 10 as your lower bound, and 30 as your upper bound so you can see the K=20 accuracy\n",
    "\n",
    "lowerbound = \n",
    "upperbound = \n",
    "plt.plot(k[lowerbound:upperbound],[s[1] for s in  gs.grid_scores_][lowerbound:upperbound],)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression\n",
    "\n",
    "KNN can be applied to a regression context\n",
    "\n",
    "Let's compare the cross-validated performance of the KNN regressor to a regression on the bike share data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bikedf = pd.read_csv(\"bikeshare.csv\")\n",
    "weather = pd.get_dummies(bikedf.weather, prefix='weather')\n",
    "predictors = [\"holiday\",\"temp\",\"humidity\",\"windspeed\", \"workingday\"]\n",
    "\n",
    "#make a data frame of just the predictors\n",
    "X = bikedf[predictors].join(weather[['weather_1', 'weather_2', 'weather_3']])\n",
    "y = bikedf['count']\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Normalizing the predictor variables will improve the performance of the KNN\n",
    "#and will not hurt the performance of the Linear Regression\n",
    "X= StandardScaler().fit_transform(X)\n",
    "\n",
    "#Let's split our data into a training and test set to cross-validate\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "\n",
    "lr = LinearRegression()\n",
    "knn = neighbors.KNeighborsRegressor(n_neighbors=30, weights='uniform')\n",
    "\n",
    "#Check the R2 fit\n",
    "print \"R2 of Linear Regression: %f\" % lr.fit(X_train,y_train).score(X_test,y_test)\n",
    "\n",
    "print \"R2 of KNN Regressor: %f\" % knn.fit(X_train,y_train).score(X_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
