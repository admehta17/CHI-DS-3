{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Formatting and Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data formatting and processing is about taking your data file, and fixing the text so that it is in the desired format.\n",
    "\n",
    "By desired format, we mean that your data is ready to be read into pandas, and analyzed using the technique's we've learned (and will learn).\n",
    "\n",
    "Remember, to analyze our data using predictive models, we have to have our predictor variables be numeric (and for regression our outcome needs to be numeric too). We also can't have any missing values (they need to either be dropped or imputed (replaced with some other value.\n",
    "\n",
    "We also need to make sure that our data is valid (e.g., not any mistakes in how it was transcribed)\n",
    "\n",
    "When we have text and dates, we need to make sure that the features we want are represented.\n",
    "\n",
    "Therefore, there are serveral ways your data can be in an undesired format, and several common things you do to fix those issues:\n",
    "\n",
    " - Contains Missing values\n",
    "     - Need Missing Values to be blanks (not NA or N/A or DIV0# or NaN)\n",
    "     - Need Missing Values to be imputed (with the median)\n",
    "     \n",
    "     \n",
    " - Numeric Issues\n",
    "     - Convert prices and strings to decimals \n",
    "         - 1,230 vs. 1230.00\n",
    "         - $443,000 vs 443000.00\n",
    "     - Impossibly large/small numbers (Income of 912101020,-5000000)\n",
    "     \n",
    "\n",
    " - Text isn't uniform\n",
    "     - Extra spaces\n",
    "     - Text is not readable (non-Ascii errors)\n",
    "     - Unnecessary characters (punctuation, numbers)\n",
    "     - Mixed case (JOHN SMITH vs. John Smith)\n",
    " \n",
    " \n",
    " - Inconsistent labeling\n",
    "     - Date formatting: Jan 16 2015 vs. January 16, 2015 vs 01-16-15 vs. 1/16/15\n",
    "     - Yes vs Y vs yes\n",
    "     - Synomyms (dog vs canine vs k9)\n",
    "       \n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting Point\n",
    "\n",
    "All of the data prepariton techniques assume that we have already imported our data into a Pandas DataFrame.\n",
    "\n",
    "So first, let make sure our data can be imported into a pandas DataFrame.\n",
    "\n",
    "Let's assume you have a data file that is ideally in some delimited format like a csv.\n",
    "\n",
    "Before do any data cleaning technique import it into a DataFrame.\n",
    "\n",
    "We'll use the read_csv command and specify that each column/field in separated by a comma (if the fields are separate by a space, then use sep= \" \", and if the fields are separated by a tab, use sep=\"\\t\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"example.csv\",sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the time this step should go smoothly, but not always.\n",
    "\n",
    "Notice how we got an error.\n",
    "\n",
    "One of the most common problems people have is that their data file may give them an error where the number of col you have a row where the number of fields doesn't match up to the number of columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a quick fix for that:\n",
    "\n",
    "We'll go through every line and make sure that it has the right number of fields.\n",
    "\n",
    "How do we go through every line and see if it has the right number of fields?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scanning through text files:\n",
    "\n",
    "- Open a text file in read-mode:\n",
    "- For every line in that file:\n",
    "- Do something to that line (like print it or split it up into pieces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Enter what your data file name is called\n",
    "fname =\"\"\n",
    "\n",
    "#Open the file in read-only binary mode and call that open file \"f\" \n",
    "with open(fname,\"rb\") as f:\n",
    "    \n",
    "    #For every line in that file\n",
    "    for line in f:\n",
    "        \n",
    "        #Split the line at the commas and turn it into a list of elements\n",
    "        fields = line.split(\",\")\n",
    "        \n",
    "        #print that list\n",
    "        print fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the code without the comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = \"\"\n",
    "with open(fname,\"rb\") as f:\n",
    "    for line in f:\n",
    "        fields = line.split(\",\")\n",
    "        print fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Viewing the problematic lines\n",
    "\n",
    "Remember, our file is causing us problems because some of the rows don't have the correct number of fields.\n",
    "\n",
    "We can see what those fields are by printing out the lines that don't have the correct number of fields\n",
    "\n",
    "To check how many elements a list has, we can use the len() function\n",
    "\n",
    "Below is the same code as above, except, we are only printing the line, if the number of elements in the line is not equal to the number of elements we should have (in this case, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fname =\"incorrect_number_of_fields.csv\"\n",
    "with open(fname,\"rb\") as f:\n",
    "    for line in f:\n",
    "        fields = line.split(\",\")\n",
    "        if len(fields) != 4:\n",
    "            print line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try it yourself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What do we do if our csv file has some lines with the wrong number of fields?\n",
    "\n",
    "Couple of options\n",
    "\n",
    "1) Delete the line\n",
    "    \n",
    "\n",
    "2) Fix it in a Text Editor\n",
    "\n",
    "\n",
    "3) Fix it in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete the line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Delete the line\n",
    "\n",
    "#Enter in your filename that holds your data\n",
    "fname =\"incorrect_number_of_fields.csv\"\n",
    "\n",
    "#How many columns/fields should each line have\n",
    "expected_columns = 4\n",
    "\n",
    "#open the file in read-binary model (\"rb\") and call the open file \"f\"\n",
    "with open(fname,\"rb\") as f:\n",
    "    \n",
    "    #for every line in the file\n",
    "    for line in f: \n",
    "        \n",
    "        #split the line on the commas to make a list of each item\n",
    "        fields = line.split(\",\") \n",
    "        \n",
    "        #if the line has as many fields as we expect \n",
    "        if len(fields) == expected_columns: \n",
    "            \n",
    "            #open a file that will contain all of our lines that\n",
    "            # have the right number of columns\n",
    "            with open(\"cleanedfile.csv\",\"ab\") as g: \n",
    "                \n",
    "                #write the line to the file\n",
    "                g.write(line) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix it in a Text Editor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#What is the filename of the csv\n",
    "fname =\"incorrect_number_of_fields.csv\"\n",
    "\n",
    "#How many columns/fields do we expect\n",
    "expected_columns = 4\n",
    "\n",
    "#Start out at line 1\n",
    "line_number = 1\n",
    "\n",
    "#Open the datafile in read-binary mode and call the open file \"f\"\n",
    "with open(fname,\"rb\") as f:\n",
    "    \n",
    "    #For every line in that file\n",
    "    for line in f:\n",
    "        \n",
    "        #Separate the elements in the line at the commas\n",
    "        fields = line.split(\",\")\n",
    "        \n",
    "        #If our line DOES NOT have the expected number of fields\n",
    "        if len(fields) != 4:\n",
    "            \n",
    "            #Print out the line number we were on, and what the text was\n",
    "            print (\"line number %i\" % line_number, fields)\n",
    "        \n",
    "        #Increment the line number by 1\n",
    "        line_number +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix it in Python\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname =\"\"\n",
    "with open(fname,\"rb\") as f:\n",
    "    for line in f:\n",
    "        fields = line.split(\",\")\n",
    "        if len(fields) == 4:\n",
    "            \n",
    "        with open(\"newfile.csv\") as g:\n",
    "            g.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Import Data in Pandas Dataframe\n",
    "\n",
    "Now that you have a csv, where every row has the same number of fields, it's ready to import into Pandas.\n",
    "\n",
    "When cleaning and manipulating your data, having it in a Pandas dataframe will make it easier to clean because you can specific columns and apply functions to them that parse the data exactly as you want.\n",
    "\n",
    "Having our data in a pandas dataframe makes it easier to work with and fix problems.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"Tweets.csv\",sep=\",\",header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code, we first import the pandas library.\n",
    "\n",
    "Next, we make read our csv file into a dataframe called df.\n",
    "\n",
    "We specify that the fields are separated by a comma (sep= \",\") and we say that the column titles (i.e., the header) is on the 1st row of the file  (header = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column names are stored in a variable called \"columns\" on the data frame object.\n",
    "\n",
    "To see the current column names in a list, simply access the column variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now though, our column names aren't very descriptive.\n",
    "\n",
    "We can replace the column names by resetting the variable to be what we want them to be.\n",
    "\n",
    "We have another file with the list of questions.\n",
    "\n",
    "Let's open that file and read the questions into a list.\n",
    "\n",
    "We'll have to make sure that there are no spaces in the variable names\n",
    "\n",
    "Then we'll set the columns of our data frame to be equal to that list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "new_column_names =[]\n",
    "with open(\"question_data.csv\", \"rb\") as f:\n",
    "    f.next()\n",
    "    for line in f:\n",
    "        if \";\" in line:\n",
    "            question=line.split(\";\")[1].split(\";\")[0]\n",
    "            question = filter(lambda x:x not in string.punctuation,question)\n",
    "            new_column_names.append(question)\n",
    "new_column_names       \n",
    "#df.columns = new_column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-naming variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we just wanted to rename one variable, we could use the rename function, and then pass on a dictionary with the old column name and the new column name. The inplace parameters makes pandas update the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.rename(columns = {'name':'username'},inplace=True)\n",
    "print df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Issue 1: Dealing with Missing Values\n",
    "\n",
    "We ideally want our pandas dataframe to know what data is missing (i.e., not present in the field where it belongs).\n",
    "\n",
    "That is, you want pandas to represent that data point with the built in Nan value. NaN stands for \"Not a Number\", and is part of the numpy library (np.nan)\n",
    "\n",
    "If our missing data is not represented as np.nan, then problems can happen later when we try to drop or impute missing fields.\n",
    "\n",
    "Therefore, it's important to make sure that missing fields are stored as np.nan\n",
    "\n",
    "To do this, you have to think of all of the possible ways missing values can be present in the text\n",
    "\n",
    "- Blanks\n",
    "- NaN\n",
    "- -999\n",
    "- Blank\n",
    "- - \n",
    "- None\n",
    "\n",
    "Then, you want to recode every instance of those values in the column so that you replace the different missing values with the same pandas compatible value (np.nan) each time.\n",
    "\n",
    "Let's look at a simple example:\n",
    "\n",
    "Below, we have a sample dataset, with a mix of real numbers, and potential missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sample_data = [1,2,3,\"-\",np.nan,None,\"NA\", \" \",\"\"]\n",
    "\n",
    "df = pd.DataFrame({\"Column1\":sample_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we just tried to drop the missing values with the built-in dropna() function, we would miss some of them because they either need to be np.nan or None to be counted as missing by pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Column1'].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we can do is make a function that takes in some content (like the values in a data frame cell), and then if that content is any of the possible ways that missing data could look, we'll return a np.nan value.\n",
    "\n",
    "We can make our data frame apply that missing data function to every single cell in a column by using the apply() function on the specific column.\n",
    "\n",
    "We'll overwrite the column by setting the cleaned result equal to the column itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def replace_missing(content):\n",
    "    if content in [\"\",\" \",np.nan,\"-\",\"NA\",None]:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return content\n",
    "\n",
    "df['Column1'] = df['Column1'].apply(replace_missing)\n",
    "\n",
    "print df['Column1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that now all of the missing values are coded the same, and we should be able to drop them using the built-in dropna() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print df['Column1'].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also impute values more easily.\n",
    "\n",
    "For example, the following code fills in the missing values (fillna) using the median value of that column ( df['Column1'].median() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Column1'].fillna(df['Column1'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Issue 2: Numeric Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume now that your data is in a dataframe and that you've made all of your missing values equal to NA so you can easily drop them or replace them.\n",
    "\n",
    "Your data still may not be analyzable because they are not in the correct \"format\" or \"type\"\n",
    "\n",
    "By format/type, we mean that numeric variables are represented as numbers and text variables are represented as strings.\n",
    "\n",
    "If you have a numeric variable stored as a string, then the analysis functions will not know how to operate on your data because the function requires numbers.\n",
    "\n",
    "In pandas, you can check on the format / type of a variable using the dtype variable of your column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "price_data = [1,2,3,4,5,6,7]\n",
    "weight_data = [10.5,14.1,30.8,28.2,5.3,6.10,7.0]\n",
    "df = pd.DataFrame({\"Prices\":price_data,\"Weight\":weight_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the type of the Prices column is an integer and the type of the Weight column is a floating point decimal. These are the two most common types of numeric data formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print df['Prices'].dtype\n",
    "print df['Weight'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can get the type for every columns using the dtypes function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) Make sure all items are numeric decimals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you know how to check what format your data is, what do you do if your column of interest is not the right type. For example, let's imagine you had a column of prices. Ideally, you want this column to be numeric so you can run a regression on it.\n",
    "\n",
    "However, because some of the data was stored with dollar signs and commas, the column is not stored as a numeric format such as integer or floating point number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_data = [\"$1.00\",2.00,.30,\" 2,000 \",\"$5,000.20\"]\n",
    "\n",
    "df = pd.DataFrame({\"Prices\":sample_data})\n",
    "print df\n",
    "print df['Prices'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the Prices variable is an object and not an integer or floating point decimal.\n",
    "\n",
    "What we want to do is, for each cell in the column, remove the dollar signs and commas, and convert them to a floaitng point number.\n",
    "\n",
    "We are first going to make a function that reads in the content of a cell.\n",
    "\n",
    "It then replaces any instance of a dollar sign with a blank, and then replaces any instance of a comma with a blank.\n",
    "\n",
    "It then tries to convert the value to a floating point number.\n",
    "\n",
    "If the value cannot be converted to a floating point, then a missing value is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def make_decimal(content):\n",
    "    content = str(content)\n",
    "    no_dollar_signs = content.replace(\"$\",\"\")\n",
    "    no_commas = no_dollar_signs.replace(\",\",\"\")\n",
    "    try: return float(no_commas)\n",
    "    except: return None\n",
    "\n",
    "df['Prices'] = df['Prices'].apply(make_decimal)\n",
    "print df['Prices']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B) Deleting Impossibly large and impossibly small values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even if your data are in their correct format, another problem that can occur is that the values were transcribed incorrectly.\n",
    "\n",
    "That is, people either put down a non-sensical value or a mistake was made when entering the data.\n",
    "\n",
    "The example below has income data, but some values are outside the realm of belief such as a negative number, or a number in the trillions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "income_data = [50000,17000,99000,98392132323,343,25000,-1]\n",
    "\n",
    "df = pd.DataFrame({\"Income\":income_data})\n",
    "print df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 1: Set it to a minimum or maximum value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to deal with the problem is to set lower and upper bounds for the data. \n",
    "\n",
    "Pandas has a built in function called clip() that allows you to specify what the minimum and maximum value should be for that column. If any value in the column is less than the minimum value, it is replaced with the minimum value. Likewise, any value in the column greater than the maximum value is replace with the maximum value you set in the clip function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Income'].clip(5000,10000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the -1 became 5000 and the number in the trillions became 10,000,000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 2:  Set it to missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are uncertain about the reason why the value is incorrect, the safest option is to make it missing, and delete the value from your data frame.\n",
    "\n",
    "Here, we'll make a function that takes in the content of the cell, and if it is lower or greater than a certain lower- or upper-bound, the function will return a None (missing) value.\n",
    "\n",
    "Otherwise, the function will return the original value.\n",
    "\n",
    "Thus, when we apply the function to a column, it will go through each value in the column, and will make a new column with the impposibly small/large values replace by a missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "income_data = [50000,1,99000,92132323343,25000,-1]\n",
    "df = pd.DataFrame({\"Income\":income_data})\n",
    "\n",
    "def delete_impossible_values(content):\n",
    "    min= 5000\n",
    "    max = 1000000\n",
    "    if content > min and content < max: return content\n",
    "    else: return None\n",
    "\n",
    "df['Income'].apply(delete_impossible_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Columns with Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to clean and format columns that are primarilty text (e.g., comments, names, posts, identifiers), then there are a couple of techniques that will make the process of working with text easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The split function\n",
    "\n",
    "A very helpful function for strings i the split() function.\n",
    "\n",
    "This function separates a string into different parts at a character or string of interest.\n",
    "\n",
    "If we have a phrase like \"How are you?\" and we split it at the spaces, we would get \"How\",\"are\",\"you\" in a list.\n",
    "\n",
    "This is a like film editor splicing a piece of film into different parts. \n",
    "\n",
    "The below example shows how to split a string on two different chracters: a space and a comma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text =\"Hello, how are you?\"\n",
    "print text.split(\" \")\n",
    "print text.split(\",\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The split function is helpful when you want only part of a string, and the that part has a consistent poistion relative to some character or text.\n",
    "\n",
    "For example, If you wanted just a person's birth year in a string of dates, you could take advantages of the fact that the month tends to go before the first space, and split the text on the space, grabbing the first element in that list.\n",
    "\n",
    "Likewise, if you wanted the day, you could take advantage of how the day comes after the first space, and is right before the first comma. That would involve two different split statements: one to split on the space and get the second element, and another to split on the comma and get the first element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Get just the month\n",
    "text = \"January 21, 2015\"\n",
    "month = text.split(\" \")[0]\n",
    "print month\n",
    "\n",
    "day = text.split(\" \")[1].split(\",\")[0]\n",
    "\n",
    "print day\n",
    "\n",
    "year = text.split(\" \")[2]\n",
    "print year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_month(content):\n",
    "    return content.split(\" \")[0]\n",
    "\n",
    "birthdates = [\"January 21, 2015\",\"June 21, 2015\",\"July 21, 2015\"]\n",
    "\n",
    "df = pd.DataFrame({\"Dates\":birthdates})\n",
    "df['Months'] = df['Dates'].apply(get_month)\n",
    "print df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inconsistent Case\n",
    "\n",
    "Another common issue is that you need all of your text to be a consistent case. Usually all lowercase is the standard.\n",
    "\n",
    "You might have text that looks like the following, where the cases are inconsistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "name_data = [\"John Smith\",\"John smith\",\"john Smith\",\"jOhN SmItH\"]\n",
    "df = pd.DataFrame({\"Names\":name_data})\n",
    "print df['Names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make all of the elements lowercase, we just have to add .str.lower() to the end of our dataframe and column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Names'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we could use an apply() function like we have been, where we make a function that ensures the text is a string, and then lowercases it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def make_lowercase(content):\n",
    "    return str(content).lower()\n",
    "\n",
    "df['Names'].apply(make_lowercase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace function\n",
    "\n",
    "Another commonly used function for strings is the replace() function.\n",
    "\n",
    "This function finds any instance of a text in a string and replaces it with something else.\n",
    "\n",
    "Let's say that you had tweets collected from Twitter, and you wanted to run text analysis on it. However, some words have a hashtag/octothorpe (#) in them (#data). You might want to remove all instances of them.\n",
    "\n",
    "You would simply use the replace function and first specify what text you want to replace in the string, and what the next text should be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweet = \"We are learning about data parsing #data\"\n",
    "print tweet.replace(\"#\",\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to use replace in the context of of an entire column, you would simply add .str.replace() to  the end of the dataframeframe and column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweet_data = [\"#data\",\"#chicago\",\"#hashtag\",\"#twitter\"]\n",
    "df = pd.DataFrame({\"tweets\":tweet_data})\n",
    "print df['tweets']\n",
    "df['tweets'].str.replace(\"#\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Counting instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To transform our text into something numeric, we might want to count all of the instances of some word in our text and save those counts to another variable.\n",
    "\n",
    "We can do this with the count() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"the cat in the hat\".count(\"the\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the .str.count() function on a specific column, we can get the counts for every cell in our variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweet_data = [\"the cat in the hat\",\"the cat\",\"green eggs and ham\"]\n",
    "df = pd.DataFrame({\"Tweets\":tweet_data})\n",
    "df['Counts'] = df['Tweets'].str.count(\"the\")\n",
    "print df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular Expressions\n",
    "\n",
    "One of the most powerful tools for processing text data are \"regular expressions\"\n",
    "\n",
    "Regular expressions allow us to create a pattern and locate or replace text that matches those patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular Expression: Subsitute\n",
    "\n",
    "Just like the replace function, regular expressions can substitute one word for another.\n",
    "\n",
    "We first import the regular expression library (re), and then use the re.sub function to tell it the text we want substituted, and the text we want in its place, and then the text for it to look through.\n",
    "\n",
    "In the example below, we'll replace all instances of \"January\" with \"Jan\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "#replace all instances of something with another\n",
    "\n",
    "#Replace all instances of January with Jan\n",
    "#Make sure to ignore the case of the text\n",
    "text = \"Jan 21, 2015; January 21, 2015\"\n",
    "re.sub(\"January\",\"Jan\",text,re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One limitation of the old replace() function we saw is that it can't handle nuances or exceptions.\n",
    "\n",
    "Let's imagine we wanted to replace all instances of \"Jan\" with \"January\"\n",
    "\n",
    "The replace function doesn't know we mean the word \"Jan\" so it replaces the \"Jan\" within \"January\" with \"January\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#replace \"Jan\" with \"January\"\n",
    "text = \"Jan 21, 2015; January 21, 2015\"\n",
    "text.replace(\"Jan\",\"January\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular expressions allow you to indicate a word boundary with the \\\\b around the word you want targeted.\n",
    "\n",
    "Because we want the word Jan (only when it occurs by itself and not part of another word), we will ask the regular expression to replace \\\\bJan\\\\b with Janauary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#replace \"Jan\" with \"January\"\n",
    "text = \"Jan 21, 2015; January 21, 2015\"\n",
    "\n",
    "#Use \\\\b to indicate a word boundary\n",
    "re.sub(\"\\\\bJan\\\\b\",\"January\",text,re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You also can compile the regular expression into an object to make it easier to use.\n",
    "\n",
    "To compile a regular expression object, just type in re.compile()\n",
    "and then enter the regular expression statement you want matched in the parenthesis. \n",
    "\n",
    "You can also indicate that the case of the text doesn't matter with re.IGNORECASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = \"Jan 21, 2015; January 21, 2015\"\n",
    "\n",
    "janreplace = re.compile(\"\\\\bJan\\\\b\",re.IGNORECASE)\n",
    "\n",
    "janreplace.sub(\"January\",text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might also have many possible things we want to substitute with the same word.\n",
    "\n",
    "Imagine that we wanted to replace not only \"Jan\" with \"January\", but also \"Ja\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#replace \"Jan\" or \"Ja\" with \"January\"\n",
    "text = \"Janu 21, 2015; Jan 21, 2015; Jan 21, 2015; January 21, 2015\"\n",
    "\n",
    "january_re = re.compile(\"\\\\bJanu\\\\b|\\\\bJan\\\\b|\\\\bJa\\\\b\",re.IGNORECASE)\n",
    "\n",
    "january_re.sub(\"January\",text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also find all of the instances of strings that match at least one of your regular expression.\n",
    "\n",
    "Additionally, you are able to count the number of times your pattern in matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print january_re.findall(text)\n",
    "print len(january_re.findall(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This functionality can be incoporated into a function as we have been using previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def replace_january(content):\n",
    "    january_re = re.compile(\"\\\\bJanu\\\\b|\\\\bJan\\\\b|\\\\bJa\\\\b\",re.IGNORECASE)\n",
    "    return january_re.sub(\"January\",content)\n",
    "\n",
    "date_data = [\"Janu 21, 2015\", \"Jan 21, 2015\",\"Jan 21, 2015\", \"January 21, 2015\"]\n",
    "df = pd.DataFrame({\"dates\":date_data})\n",
    "df['dates'].apply(replace_january)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B) Remove Extra Spaces\n",
    "\n",
    "Regular expressions can also do operations on non-ascii characters like spaces.\n",
    "\n",
    "In regular expressions, space are represented as \\s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = \"Hello how are you\"\n",
    "re.sub(\"\\s\",\"_\",text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular expressions also use a + sign to include the possibility of a character repeating itself.\n",
    "\n",
    "For example, if you wanted to replace all instances of \"no\" (including nooo,nooooo,nooooooo,and nooooooooo) with just \"no\", you would  use the follow expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = \"Noooooooooooooo. It can't be\"\n",
    "no_replace = re.compile(\"no+\",re.IGNORECASE)\n",
    "no_replace.sub(\"no\",text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting those two tricks together, we can replace all extra spaces with just a single space by using a regular expression \\s+ to find all instances of spaces (including those that reoccur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text= \"This    text    has a    lot       of extra   spaces\"\n",
    "no_replace = re.compile(\"\\s+\")\n",
    "no_replace.sub(\" \",text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another commonly used symbol in regular expressions is the . sign.\n",
    "It means \"anything\" and is like a wildcard in poker that can represent any card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = \"cans cane canes\"\n",
    "re.sub(\"can.\",\"can\",text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's replace the word in between < tag\\> and < /tag>\n",
    "\n",
    "Any time we see a non-alphanumeric character like \"<\", we have to place a \"\\\\\" before it.\n",
    "\n",
    "To group things together, we use parentheses.\n",
    "\n",
    "So (.?) groups the wildcard and the optional statement together.\n",
    "\n",
    "The + sign after it tells it to keep going until you run in the next piece of text, which is < /tag>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = \"<tag>Hello</tag>\"\n",
    "print text\n",
    "re.sub(\"\\<tag\\>(.?)+\\<\\/tag\\>\",\"<tag>Goodbye</tag>\",text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Unwanted/Uncessary Types of Characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful function is te filter function.\n",
    "\n",
    "Filter creates a list of elements, for which a function returns true.\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lst = [1,2,3,4]\n",
    "\n",
    "filter(lambda x: x < 3,lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lst = [1,2,3,4]\n",
    "\n",
    "filter(lambda x: x in [1,3],lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i) Remove punctuation\n",
    "\n",
    "We can use the filter function to remove characters/words that are/aren't in a list we want.\n",
    "\n",
    "For example, imagine we don't want any punctuation in our text.\n",
    "\n",
    "We can use the list of punctuation marks found in the string library in our true/false check in the filter statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we will use the filter function to only return the characters that are not in this punctuation list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "text= \"Hello, how are you?\"\n",
    "filtered_text = filter(lambda x: x not in string.punctuation, text)\n",
    "print filtered_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extend this concept to words, and only return words that are not in a forbidden list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "forbidden_words=[\"the\",\"and\",\"is\",\"are\",\"in\"]\n",
    "text= \"the cat in the hat\"\n",
    "words = text.split(\" \")\n",
    "filtered_text = filter(lambda x: x not in forbidden_words, words)\n",
    "print filtered_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii) Leave only letters (and spaces)\n",
    "\n",
    "We might want to remove anything that is not an ascii letter (abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ).\n",
    "\n",
    "or a space \" \"\n",
    "\n",
    "So, we can combine those two lists and filter out characters not in that list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import string\n",
    "text= \"I'll meet you at 10 tonight\"\n",
    "filtered_text = filter(lambda x: x in string.ascii_letters+\" \", text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iii) Leave only numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import string\n",
    "text= \"I'll meet you at 10 tonight\"\n",
    "filtered_text = filter(lambda x: x in string.digits, text)\n",
    "print filtered_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iv) Remove non-printable characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\"These are non-printable characters: µ¶Ö\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import string\n",
    "text= \"These are non-printable characters: µ¶Ö\"\n",
    "filtered_text = filter(lambda x: x in string.printable, text)\n",
    "print filtered_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Issue 3: Inconsistent Labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, people put down a variety of responses on an open-ended sheet and you want to make the responses consistent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-standard labels\n",
    "\n",
    "A frequent inconsistent labelling is when people put down varying ways to say \"yes\" or \"no\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "response_data = [\"yes\",\"Yes\",\"no\",\"No\",\"y\",\"N\"]\n",
    "df = pd.DataFrame({\"Response\":response_data})\n",
    "print df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could solve his by just taking the first letter of the response and lowercasing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Response'].apply(lambda x: x[0].lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more generalizable way of handling the problem is to first look at all of the unique values entered for this column, and then for each possible response, you make a recode dictionary that has the response as the key, and the recoded response that you desire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"Response\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll take all the different ways people responded to this question, and say what numeric value we want each one to be.\n",
    "\n",
    "Then, we'll have these values be remapped used the map() function on our dataframe's column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recodes= {\n",
    "    \"yes\":1,\n",
    "    \"Yes\":1,\n",
    "    \"y\":1,\n",
    "    \"No\":0,\n",
    "    \"N\":0,\n",
    "    \"no\":0\n",
    "    }\n",
    "df['Response'].map(recodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A third way of handling inconsistent coding is to use the replace fuction and indicate what you want the old value to be recoded as.\n",
    "\n",
    "The old value is the first parameter and the second value is what you want the new value to be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Response'].replace(\"yes\",\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "values = range(1,100)\n",
    "df = pd.DataFrame({'Column1':values})\n",
    "df['Groups'] = pd.cut(df['Column1'],[0,10,20,30,40,50,60,70,80,90,100])\n",
    "print df['Groups'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recodes= {\n",
    "    \"(0, 10]\":\"Group1\",\n",
    "    \"(10, 20]\":\"Group2\",\n",
    "    \"(20, 30]\":\"Group3\",\n",
    "    \"(30, 40]\":\"Group4\",\n",
    "    \"(40, 50]\":\"Group5\",\n",
    "    \"(50, 60]\":\"Group6\",\n",
    "    \"(60, 70]\":\"Group7\",\n",
    "    \"(70, 80]\":\"Group8\",\n",
    "    \"(80, 90]\":\"Group9\",\n",
    "    \"(90, 100]\":\"Group10\"\n",
    "    }\n",
    "df['Groups'].map(recodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can specify what the labels are for each group ahead of time using the labels command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "values = range(1,100)\n",
    "labels = [\"Group \" + str(i) for i in range(1,11)]\n",
    "df = pd.DataFrame({'Column1':values})\n",
    "df['Groups'] = pd.cut(df['Column1'],[0,10,20,30,40,50,60,70,80,90,100],labels=labels)\n",
    "print df['Groups']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
