{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Getting factual data/info specific to our question from WolframAlpha\n",
    "\n",
    "One especially useful API for Data Science is the Wolfram Alpha API. \n",
    "\n",
    "Wolfram Alpha is a \"knowlede engine\", where, like a search engine, you can ask specific queries about a topic (\"What is the unemployment rate in Illinois in 2013\"). However, unlike a search engine, the answers are returned as factual information in a simple structured format (8.4%).\n",
    " \n",
    "First let us import the two libraries we need to access an API and parse the information:\n",
    "\n",
    "Remember, the requests library allows us to connect to the API and pass along the variables we are requesting.\n",
    "\n",
    "The lxml.etree library allows us to parse the XML returned by an API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import lxml.etree as ET\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Querying Financial Information\n",
    "\n",
    "Next, we can create a search query about a topic of interest that most likely has a factual answer.\n",
    "\n",
    "If you are interested in finance, you can ask for the closing price of the New York Stock Echange (NYSE) on a specific day.\n",
    "\n",
    "This is what the request would look like if you used the web interface: https://www.wolframalpha.com/input/?i=Closing+price+of+NYSE+on+May+6th+2014\n",
    "\n",
    "Here is a list of all kinds of topics you ask Wolfram Alpha: https://www.wolframalpha.com/examples/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#make a query variable that holds our specific request\n",
    "query=\"Closing price of NYSE on May 6th 2014\"\n",
    "\n",
    "#submit the request and write our query at the end of the request\n",
    "content= requests.get(\"http://api.wolframalpha.com/v2/query?appid=JRUT3Q-J7X5RLLY5U&input=\"+query)    \n",
    "\n",
    "#Get the XML response returned by the API\n",
    "#.text part gets the just the plaintext information from the XML request\n",
    "#the . utf-8 part encodes the text to handle a broader range of characters\n",
    "content_string = content.text.encode(\"utf-8\")\n",
    "\n",
    "#note that sometimes the request timesout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pass on the XML to our XML parser\n",
    "doc = ET.fromstring(str(content_string))\n",
    "\n",
    "#Show the content\n",
    "print ET.tostring(doc, pretty_print=True)\n",
    "#You should see an XML tree returned. Within this XML tree is our answer\n",
    "#Our expected result is 10630. Do you see that number in the tree\n",
    "\n",
    "#if you look at the printed XML returned by the request (above), you can see that our result is within a tag that has the title \"Result\"\n",
    "#Within the \"Result\" tag is another tag called \"subpod\" that holds out result, and our actual result within the tag called \"plaintext\"\n",
    "#go through the tree saying you want the information in the <plaintext> tags which is in the <subpod > tag, which is in the <pos title=\"Result\"> tag\n",
    "\n",
    "#We ignore the queryresult tag at the top because it is the root tag, and everything is under it\n",
    "\n",
    "answer = doc.find('pod[@title=\"Result\"]/subpod/plaintext')\n",
    "\n",
    "#print out the the data that was retrieved\n",
    "print answer.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Automatic collection of data\n",
    "\n",
    "Let's say that you want the NSYE closing price, not just for one day, but all the weekdays.\n",
    "\n",
    "If you know the days you want, you can construct a \"for loop\" to automate data collection and retreive results for each day\n",
    "\n",
    "Here, we will collect the data for the closing price of the New York and the average temperature on that day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting a list of all of the weekdays in 2015\n",
    "\n",
    "Don't worry about the specifics of this code.\n",
    "\n",
    "It allows us to provide a date range and the days of the week we want, and then get a list of those days in \"Month Day, Year format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dateutil.rrule import DAILY, rrule, MO, TU, WE, TH, FR\n",
    "from dateutil.parser import parse\n",
    "from time import strftime\n",
    "datelist =  rrule(DAILY, dtstart=parse(\"2015-01-01\"), until=parse(\"2015-12-31\"), byweekday=(MO,TU,WE,TH,FR))\n",
    "dates = [date.strftime(\"%b %d, %Y\") for date in datelist]\n",
    "print dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A function to retrieve an answer from the Wolfram Alpha given a specific query\n",
    "\n",
    "Because we are going to be querying the Wolfram Alpha API for each date, we can simplify the code by turning the request code into a function that we can call in our for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#we'll need the time library to tell our script to wait in case something goes wrong\n",
    "import time\n",
    "\n",
    "#set up a funciton called \"ask_wolfram\" that take a string query as an input\n",
    "def ask_wolfram(query):\n",
    "    \n",
    "    #We want to create a variable called \"success\" that changes if we get a result from the API\n",
    "    success = False\n",
    "    \n",
    "    #Keep running the script until success is True\n",
    "    while success == False:\n",
    "        \n",
    "        #Send the API request with our string and save the result as a variable called content\n",
    "        content= requests.get(\"http://api.wolframalpha.com/v2/query?input=\"+query+\"&appid=JRUT3Q-J7X5RLLY5U\")    \n",
    "        \n",
    "        #get the XML content returned from the API and encode it in utf-8, which can handle special characters better\n",
    "        content_string = content.text.encode('utf-8')\n",
    "        \n",
    "        #pass the XML to our XML parser\n",
    "        doc = ET.fromstring(str(content_string))\n",
    "        \n",
    "        #find our results in the XML, which are \n",
    "        #save those results to the answer variable\n",
    "        answer = doc.find('./pod[@title=\"Result\"]/subpod/plaintext')\n",
    "        \n",
    "        #If we got nothing from the API, then the answer variable is a None type variable\n",
    "        \n",
    "        #If the answer is not None, and we get something, change success to True\n",
    "        if answer!= None:  success = True\n",
    "        #otherwise, we should wait for half a second before trying the request again\n",
    "        else: time.sleep(.5)\n",
    "    #Once we get out of the above loop, let's break out of the function by returning the answer, making sure it is encoded correctly\n",
    "    return answer.text.encode('utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The for loop that collects the data we want for all dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import lxml.etree as ET\n",
    "import requests\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "\n",
    "#Make an empty list to hold all of the data we collect from Wolfram Alpha. This list will hold lists that contain the Date, Closing Price, and Temperature for that day.\n",
    "alldata=[]\n",
    "#We will only collect the first ten dates to show the process. Collecing the full year would take a much longer time, but you would just take out the [0:10] part\n",
    "for date in dates[0:3]:\n",
    "   \n",
    "    #write the query to get the closing price of the NSYE on a specific day\n",
    "    query=\"Closing price of NYSE on \" + date\n",
    "    \n",
    "    #Get the closing price from Wolfram Alpha\n",
    "    closing_amt = ask_wolfram(query)\n",
    "    \n",
    "    #Make sure that the returned result is a number\n",
    "    closing_amt=float(closing_amt)\n",
    "    \n",
    "    #write the query to get the average temperature in New York on that day    \n",
    "    query=\"Average temperature in New York on \" + date\n",
    "    \n",
    "    #get the temperature value from Wolfram Alpha\n",
    "    temperature_amt = ask_wolfram(query)\n",
    "    \n",
    "    #Make sure the temperature is treated as a number, and doesn't have the degree symbol (splitting \"90 oF at the space and getting the first element does this)\n",
    "    temperature_amt =float(temperature_amt.split(\" \")[0])\n",
    "    \n",
    "    \n",
    "    #stock_df = stock_df.append(day_data,ignore_index=True)\n",
    "    print date\n",
    "    alldata.append([date,closing_amt,temperature_amt])\n",
    "\n",
    "#Make a pandas DataFrame out of the data we collected    \n",
    "stock_df = pd.DataFrame(alldata,columns=[\"Date\", \"ClosingPrice\", \"Temperature\" ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Saving / Loading the results to/from a csv\n",
    "\n",
    "We can save the results we collected as a csv file. We can then load them in again and put into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Don't save the results you have. A csv file with the full information is already saved in the folder\n",
    "#If you wanted to save them, you would use the following code\n",
    "#stock_df.to_csv(\"StockExchangeWeather.csv\",sep=\",\")\n",
    "\n",
    "#This line reads in the saved csv as a pandas DataFrame named stock_df\n",
    "stock_df = pd.read_csv(\"StockExchangeWeather.csv\",sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing trends\n",
    "\n",
    "\n",
    "We can visualize the data to see if there are any immediately noticable trends of the closing price changing when the weather is hotter or colder. \n",
    "\n",
    "When you run the code, do you see any relationship between the temperature in New York and the closing price of the New York Stock Exchange? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "#plot a scatterplot of the data\n",
    "#the x-axis (bottom of the plot) is the hypothesized predictor variable (Temperature)\n",
    "#The y-axis (left of the plot) is the outcome variable of interest (Closing Price)\n",
    "# The \"o\" indicates that we want data represented as circles, not X's or lines\n",
    "plt.plot( stock_df[\"Temperature\"],stock_df['ClosingPrice'], \"o\")\n",
    "\n",
    "#show the figure\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Try it yourself: The Wikipedia API\n",
    "\n",
    "The following is the API url for Wikipedia to retrieve the abstract (intro paragraph) of a Wikipedia artlce\n",
    "\n",
    "\"https://en.wikipedia.org/w/api.php?action=query&prop=extracts&format=xml\"\n",
    "\n",
    "There is also a parameter called \"titles\" you need to add the end of the url.\n",
    "\n",
    "Your goal is to make a request to the Wikipedia API and extract the article text for any article title. Make sure to check what the title would be on Wikipedia.\n",
    "\n",
    "Save the article text (not the XML) as a variable calle: article\n",
    "\n",
    "Hint: \n",
    "\n",
    "Print the raw XML first to see what the XML tree looks like and where the article text is stored\n",
    "\n",
    "If you need to access tags within tags from the parsed XML, use the following pattern in your code:\n",
    "\n",
    "doc.find('./outermosttag/innertag/innermosttag').text\n",
    "\n",
    "outermosttag,innertag, and innermosttag should be named based on what they are called in the XML tree\n",
    "\n",
    "Viewing the XML in your web browser may help you to visualize the tree better.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lxml.etree as ET\n",
    "import requests\n",
    "\n",
    "#make a query variable that holds our specific request\n",
    "title=\"Association football\"\n",
    "\n",
    "#submit the request and write our query at the end of the request\n",
    "content= requests.get(\"https://en.wikipedia.org/w/api.php?action=query&prop=extracts&format=xml&titles=\"+title)    \n",
    "content_string = content.text.encode(\"utf-8\")\n",
    "doc = ET.fromstring(content_string)\n",
    "\n",
    "answer = doc.find(\"query/pages/page/extract\")\n",
    "print answer.text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
